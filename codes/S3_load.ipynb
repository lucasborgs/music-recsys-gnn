{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b38b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Raiz do Projeto encontrada: /Users/lucasborges/Downloads/TCC\n",
      "âš™ï¸ ConfiguraÃ§Ã£o carregada de: /Users/lucasborges/Downloads/TCC/conf/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CARGA DE CONFIGURAÃ‡ÃƒO\n",
    "# ==============================================================================\n",
    "\n",
    "def find_project_root(anchor_file=\"conf/config.yaml\"):\n",
    "    \"\"\"\n",
    "    Sobe os diretÃ³rios a partir do notebook atual atÃ© encontrar\n",
    "    a pasta onde 'conf/config.yaml' existe.\n",
    "    \"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    \n",
    "    # Tenta no diretÃ³rio atual e sobe atÃ© o raiz do sistema\n",
    "    for parent in [current_path] + list(current_path.parents):\n",
    "        potential_config = parent / anchor_file\n",
    "        if potential_config.exists():\n",
    "            return parent\n",
    "            \n",
    "    raise FileNotFoundError(f\"NÃ£o foi possÃ­vel encontrar a raiz do projeto contendo '{anchor_file}'.\")\n",
    "\n",
    "# 1. Definir BASE_DIR (Raiz do Projeto)\n",
    "try:\n",
    "    BASE_DIR = find_project_root(\"conf/config.yaml\")\n",
    "    print(f\"ðŸ“‚ Raiz do Projeto encontrada: {BASE_DIR}\")\n",
    "except FileNotFoundError as e:\n",
    "    # Fallback manual caso a busca automÃ¡tica falhe (ajuste se necessÃ¡rio)\n",
    "    print(\"Busca automÃ¡tica falhou. Usando fallback.\")\n",
    "    BASE_DIR = Path(\"/Users/lucasborges/Downloads/TCC\")\n",
    "\n",
    "# 2. Carregar o YAML da pasta conf\n",
    "CONFIG_PATH = BASE_DIR / \"conf/config.yaml\"\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. ATALHOS E VARIÃVEIS GLOBAIS\n",
    "# ==============================================================================\n",
    "\n",
    "# Atalhos dos DicionÃ¡rios do YAML\n",
    "# P['raw'] vai virar algo como: /Users/.../TCC/data/raw\n",
    "P = {k: BASE_DIR / v for k, v in config['paths'].items()} # P de Paths\n",
    "F = config['files']                                       # F de Files\n",
    "PM = config['params']                                     # PM de Params\n",
    "\n",
    "print(f\"âš™ï¸ ConfiguraÃ§Ã£o carregada de: {CONFIG_PATH}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PONTE DE VARIÃVEIS\n",
    "# ==============================================================================\n",
    "\n",
    "# Caminhos de Arquivos (Apontando para o YAML)\n",
    "TRAIN_EMB_PATH       = P['processed'] / F['track_embeddings']\n",
    "NEW_EMB_PATH         = P['processed'] / F['new_track_embeddings']\n",
    "X_TRAIN_PATH         = P['processed'] / F['train_features']\n",
    "X_TEST_PATH          = P['processed'] / F['test_features']\n",
    "\n",
    "\n",
    "# Se nÃ£o estiver no YAML, usa o caminho construÃ­do:\n",
    "TRACKS_COMPLETE_PATH = P['interim']   / \"df_tracks_complete_v5.parquet\"\n",
    "\n",
    "# Caminhos de Grafos\n",
    "# Verifica se as chaves existem no yaml, senÃ£o usa padrÃ£o\n",
    "MATCHING_MAP_PATH    = P.get('graphs_coarsened', P['graphs_bipartite']) / F['matching_map']\n",
    "SUPER_EMB_PATH       = P.get('graphs_super', P['graphs_bipartite'])     / F['super_embeddings']\n",
    "\n",
    "# ParÃ¢metros\n",
    "SEED                 = PM['seed']\n",
    "\n",
    "# ConfiguraÃ§Ãµes Visuais PadrÃ£o\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387d5629-b8d6-4857-990b-963258a09c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos os arquivos carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Dados Raw\n",
    "df_playlists = pd.read_parquet(P['raw'] / \"df_playlists_v0.parquet\")\n",
    "df_tracks    = pd.read_parquet(P['raw'] / \"df_tracks_v0.parquet\")\n",
    "dim_artists  = pd.read_parquet(P['raw'] / \"dim_artists.parquet\")\n",
    "dim_albums   = pd.read_parquet(P['raw'] / \"dim_albums.parquet\")\n",
    "\n",
    "# Dados Processados \n",
    "df_full      = pd.read_parquet(P['processed'] / \"df_full.parquet\")\n",
    "X_train      = pd.read_parquet(P['processed'] / F['train_features'])\n",
    "X_test       = pd.read_parquet(P['processed'] / F['test_features'])\n",
    "\n",
    "print(\"Todos os arquivos carregados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb72ded6-48ef-429a-be80-8de2f2d8bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab9c67f-291f-4e26-b3f8-60287905458a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de tracks vÃ¡lidas: 324,305\n",
      "Registros originais em df_tracks: 6,685,101\n",
      "Registros apÃ³s filtro: 2,821,538\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# ETAPA 1: Filtrar tracks vÃ¡lidas (presentes em X_train_v1)\n",
    "# ==============================================================================\n",
    "valid_tracks = set(X_train['track_uri'].unique())\n",
    "print(f\"Total de tracks vÃ¡lidas: {len(valid_tracks):,}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# ETAPA 2: Filtrar df_tracks para manter apenas tracks vÃ¡lidas\n",
    "# ==============================================================================\n",
    "df_tracks_filtered = df_tracks[df_tracks['track_uri'].isin(valid_tracks)].copy()\n",
    "print(f\"Registros originais em df_tracks: {len(df_tracks):,}\")\n",
    "print(f\"Registros apÃ³s filtro: {len(df_tracks_filtered):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0870327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def build_bipartite_from_dfs(df_playlists, df_tracks,\n",
    "                             alpha=1.0, beta=0.3, gamma=0.5,\n",
    "                             pos_lambda=3.0, half_life_days=90):\n",
    "    # Merge para trazer num_tracks e modified_at\n",
    "    df = df_tracks.merge(\n",
    "        df_playlists[['pid','num_tracks','modified_at']],\n",
    "        on='pid', how='left'\n",
    "    )\n",
    "\n",
    "    # --- posWeight ---\n",
    "    L = df['num_tracks'].clip(lower=1)\n",
    "    pos_norm = np.where(L>1, df['pos']/(L-1), 0.0)\n",
    "    pos_weight = np.exp(-pos_lambda * pos_norm)\n",
    "\n",
    "    # --- timeWeight ---\n",
    "    now = pd.Timestamp.utcnow().timestamp()\n",
    "    delta_days = (now - df['modified_at']) / 86400.0  # segundos -> dias\n",
    "    time_weight = np.exp(-np.log(2) * (delta_days / half_life_days))\n",
    "\n",
    "    # --- peso final ---\n",
    "    w = alpha*1.0 + beta*pos_weight + gamma*time_weight\n",
    "    w = w / np.sqrt(L)  # normalizar por tamanho da playlist\n",
    "\n",
    "    # --- Mapas pâ†’linha, mâ†’coluna ---\n",
    "    p_index = pd.Index(df['pid'].unique(), name='playlist_id')\n",
    "    m_index = pd.Index(df['track_uri'].unique(), name='track_id')\n",
    "\n",
    "    p_codes = df['pid'].map({pid:i for i,pid in enumerate(p_index)}).to_numpy()\n",
    "    m_codes = df['track_uri'].map({tid:i for i,tid in enumerate(m_index)}).to_numpy()\n",
    "\n",
    "    # Matriz esparsa Playlist Ã— MÃºsica\n",
    "    B = coo_matrix((w, (p_codes, m_codes)),\n",
    "                   shape=(len(p_index), len(m_index))).tocsr()\n",
    "\n",
    "    return B, p_index, m_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c303e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando matriz bipartida B com build_bipartite_from_dfs...\n",
      "Matriz B criada!\n",
      "Shape de B: (97948, 324305)  (playlists x tracks)\n",
      "NÃºmero de entradas nÃ£o nulas (arestas): 2,782,022\n",
      "\n",
      "======================================================================\n",
      "INFORMAÃ‡Ã•ES DA REDE BIPARTIDA (a partir da matriz B)\n",
      "======================================================================\n",
      "Ã‰ bipartida: True\n",
      "\n",
      "Total de nÃ³s: 422,253  (playlists=97,948, tracks=324,305)\n",
      "Total de arestas (pares playlist-track com w_pm > 0): 2,782,022\n",
      "Densidade (nnz / (|P| * |M|)): 8.758129e-05\n",
      "\n",
      "NÃ³s do tipo playlist: 97,948\n",
      "NÃ³s do tipo track: 324,305\n",
      "\n",
      "--- Grau das Playlists (nÃºmero de mÃºsicas por playlist) ---\n",
      "MÃ©dia:   28.40\n",
      "Mediana: 19.00\n",
      "MÃ­nimo:  1\n",
      "MÃ¡ximo:  224\n",
      "\n",
      "--- Grau das Tracks (nÃºmero de playlists que contÃªm cada mÃºsica) ---\n",
      "MÃ©dia:   8.58\n",
      "Mediana: 1.00\n",
      "MÃ­nimo:  1\n",
      "MÃ¡ximo:  3105\n",
      "\n",
      "--- Pesos das arestas w_pm ---\n",
      "Peso mÃ©dio: 0.1247\n",
      "Peso mÃ­nimo: 0.0642\n",
      "Peso mÃ¡ximo: 2.4453\n",
      "Percentis [1,25,50,75,90,99]: [0.0668 0.0872 0.1095 0.1456 0.1925 0.3177]\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# ETAPA 3: Criar a matriz bipartida B (playlists x tracks)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\nCriando matriz bipartida B com build_bipartite_from_dfs...\")\n",
    "\n",
    "B, p_index, m_index = build_bipartite_from_dfs(\n",
    "    df_playlists=df_playlists,\n",
    "    df_tracks=df_tracks_filtered,\n",
    "    alpha=1.0,\n",
    "    beta=0.3,\n",
    "    gamma=0.5,\n",
    "    pos_lambda=3.0,\n",
    "    half_life_days=90\n",
    ")\n",
    "\n",
    "print(\"Matriz B criada!\")\n",
    "print(f\"Shape de B: {B.shape}  (playlists x tracks)\")\n",
    "print(f\"NÃºmero de entradas nÃ£o nulas (arestas): {B.nnz:,}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# ETAPA 4: Validar a rede bipartida a partir de B\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INFORMAÃ‡Ã•ES DA REDE BIPARTIDA (a partir da matriz B)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "nP, nM = B.shape\n",
    "nnz = B.nnz\n",
    "\n",
    "# 1) Ã‰ bipartida?\n",
    "# Por construÃ§Ã£o, sim: linhas = playlists, colunas = tracks.\n",
    "is_bipartite = True\n",
    "print(f\"Ã‰ bipartida: {is_bipartite}\")\n",
    "\n",
    "# 2) EstatÃ­sticas gerais\n",
    "print(f\"\\nTotal de nÃ³s: {nP + nM:,}  (playlists={nP:,}, tracks={nM:,})\")\n",
    "print(f\"Total de arestas (pares playlist-track com w_pm > 0): {nnz:,}\")\n",
    "density = nnz / (nP * nM) if nP * nM > 0 else 0.0\n",
    "print(f\"Densidade (nnz / (|P| * |M|)): {density:.6e}\")\n",
    "\n",
    "# 3) \"Conjuntos\" de nÃ³s (sÃ³ para manter o paralelo com o cÃ³digo antigo)\n",
    "print(f\"\\nNÃ³s do tipo playlist: {nP:,}\")\n",
    "print(f\"NÃ³s do tipo track: {nM:,}\")\n",
    "\n",
    "# 4) EstatÃ­sticas de grau (em B, Ã© nÃºmero de entradas !=0 por linha/coluna)\n",
    "#    Playlist: quantas mÃºsicas ela contÃ©m\n",
    "#    Track: em quantas playlists aparece\n",
    "\n",
    "# CSR: indptr guarda offsets das linhas => diff = nnz por linha\n",
    "playlist_degrees = np.diff(B.indptr)           # nÂº de tracks por playlist\n",
    "# Colunas: usa CSC, mesmo raciocÃ­nio\n",
    "Bc = B.tocsc()\n",
    "track_degrees = np.diff(Bc.indptr)             # nÂº de playlists por track\n",
    "\n",
    "print(f\"\\n--- Grau das Playlists (nÃºmero de mÃºsicas por playlist) ---\")\n",
    "print(f\"MÃ©dia:   {np.mean(playlist_degrees):.2f}\")\n",
    "print(f\"Mediana: {np.median(playlist_degrees):.2f}\")\n",
    "print(f\"MÃ­nimo:  {np.min(playlist_degrees)}\")\n",
    "print(f\"MÃ¡ximo:  {np.max(playlist_degrees)}\")\n",
    "\n",
    "print(f\"\\n--- Grau das Tracks (nÃºmero de playlists que contÃªm cada mÃºsica) ---\")\n",
    "print(f\"MÃ©dia:   {np.mean(track_degrees):.2f}\")\n",
    "print(f\"Mediana: {np.median(track_degrees):.2f}\")\n",
    "print(f\"MÃ­nimo:  {np.min(track_degrees)}\")\n",
    "print(f\"MÃ¡ximo:  {np.max(track_degrees)}\")\n",
    "\n",
    "# 5) (Opcional) EstatÃ­sticas dos pesos w_pm\n",
    "w = B.data\n",
    "print(f\"\\n--- Pesos das arestas w_pm ---\")\n",
    "print(f\"Peso mÃ©dio: {w.mean():.4f}\")\n",
    "print(f\"Peso mÃ­nimo: {w.min():.4f}\")\n",
    "print(f\"Peso mÃ¡ximo: {w.max():.4f}\")\n",
    "print(\"Percentis [1,25,50,75,90,99]:\", np.round(np.percentile(w, [1,25,50,75,90,99]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15aa3da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ANÃLISE DE COMPONENTES CONECTADOS\n",
      "======================================================================\n",
      "Tamanho de B: 97,948 playlists x 324,305 tracks\n",
      "\n",
      "NÃºmero total de componentes conectados: 353\n",
      "\n",
      "DistribuiÃ§Ã£o de tamanhos das componentes:\n",
      "- Maior componente (LCC): 418,754 nÃ³s\n",
      "- Segunda maior: 147 nÃ³s\n",
      "- Terceira maior: 117 nÃ³s\n",
      "\n",
      "LCC representa 99.17% dos nÃ³s totais\n",
      "\n",
      "NÃ³s na LCC: 418,754\n",
      "- Playlists na LCC: 97,594\n",
      "- Tracks na LCC: 321,160\n",
      "\n",
      "Componentes isoladas/pequenas:\n",
      "- Quantidade: 352\n",
      "- Tamanho mÃ©dio: 9.94 nÃ³s\n",
      "- Tamanho mÃ­nimo: 2 nÃ³s\n",
      "- Tamanho mÃ¡ximo: 147 nÃ³s\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import bmat\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "# ==============================================================================\n",
    "# ETAPA 6: AnÃ¡lise de Componentes Conectados (via matriz B)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANÃLISE DE COMPONENTES CONECTADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# B: matriz bipartida (playlists x tracks) em CSR\n",
    "nP, nM = B.shape\n",
    "print(f\"Tamanho de B: {nP:,} playlists x {nM:,} tracks\")\n",
    "\n",
    "# Monta matriz de adjacÃªncia do grafo bipartido:\n",
    "# A = [[0, B],\n",
    "#      [B.T, 0]]\n",
    "A = bmat([[None, B],\n",
    "          [B.T, None]], format=\"csr\")\n",
    "\n",
    "# Obter componentes conectados\n",
    "n_components, labels = connected_components(A, directed=False, return_labels=True)\n",
    "\n",
    "print(f\"\\nNÃºmero total de componentes conectados: {n_components:,}\")\n",
    "\n",
    "# labels: tamanho nP + nM\n",
    "#  - primeiros nP Ã­ndices correspondem Ã s playlists (linhas de B)\n",
    "#  - Ãºltimos nM Ã­ndices correspondem Ã s tracks (colunas de B)\n",
    "labels_P = labels[:nP]\n",
    "labels_M = labels[nP:]\n",
    "\n",
    "# Tamanho de cada componente\n",
    "# comp_id -> tamanho\n",
    "component_ids, component_sizes = np.unique(labels, return_counts=True)\n",
    "\n",
    "# Ordenar tamanhos (decrescente)\n",
    "component_sizes_sorted = sorted(component_sizes.tolist(), reverse=True)\n",
    "\n",
    "print(f\"\\nDistribuiÃ§Ã£o de tamanhos das componentes:\")\n",
    "print(f\"- Maior componente (LCC): {component_sizes_sorted[0]:,} nÃ³s\")\n",
    "if len(component_sizes_sorted) > 1:\n",
    "    print(f\"- Segunda maior: {component_sizes_sorted[1]:,} nÃ³s\")\n",
    "if len(component_sizes_sorted) > 2:\n",
    "    print(f\"- Terceira maior: {component_sizes_sorted[2]:,} nÃ³s\")\n",
    "\n",
    "# Percentual da LCC\n",
    "total_nodes = nP + nM\n",
    "lcc_size = component_sizes_sorted[0]\n",
    "lcc_percentage = (lcc_size / total_nodes) * 100 if total_nodes > 0 else 0.0\n",
    "print(f\"\\nLCC representa {lcc_percentage:.2f}% dos nÃ³s totais\")\n",
    "\n",
    "# Identificar ID da LCC\n",
    "largest_comp_id = component_ids[np.argmax(component_sizes)]\n",
    "\n",
    "# Ãndices (posiÃ§Ãµes) dos nÃ³s na LCC\n",
    "playlists_in_lcc_idx = np.where(labels_P == largest_comp_id)[0]\n",
    "tracks_in_lcc_idx    = np.where(labels_M == largest_comp_id)[0]\n",
    "\n",
    "print(f\"\\nNÃ³s na LCC: {lcc_size:,}\")\n",
    "print(f\"- Playlists na LCC: {len(playlists_in_lcc_idx):,}\")\n",
    "print(f\"- Tracks na LCC: {len(tracks_in_lcc_idx):,}\")\n",
    "\n",
    "# Se quiser os IDs reais (pid / track_uri), pode mapear assim:\n",
    "# playlists_in_lcc_ids = p_index[playlists_in_lcc_idx]\n",
    "# tracks_in_lcc_ids    = m_index[tracks_in_lcc_idx]\n",
    "\n",
    "# EstatÃ­sticas das componentes pequenas\n",
    "if n_components > 1:\n",
    "    small_components = component_sizes_sorted[1:]\n",
    "    print(f\"\\nComponentes isoladas/pequenas:\")\n",
    "    print(f\"- Quantidade: {len(small_components):,}\")\n",
    "    print(f\"- Tamanho mÃ©dio: {np.mean(small_components):.2f} nÃ³s\")\n",
    "    print(f\"- Tamanho mÃ­nimo: {min(small_components)} nÃ³s\")\n",
    "    print(f\"- Tamanho mÃ¡ximo: {max(small_components)} nÃ³s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ae7444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CRIANDO MATRIZ B APENAS COM A LCC\n",
      "======================================================================\n",
      "\n",
      "Matriz B_lcc criada!\n",
      "Playlists na LCC: 97,594\n",
      "Tracks na LCC: 321,160\n",
      "Total de nÃ³s na LCC: 418,754\n",
      "Total de arestas na LCC: 2,778,857\n",
      "Densidade da LCC: 8.865876e-05\n",
      "\n",
      "--- Grau das Playlists na LCC (nÂº de mÃºsicas por playlist) ---\n",
      "MÃ©dia:   28.47\n",
      "Mediana: 19.00\n",
      "MÃ­nimo:  1\n",
      "MÃ¡ximo:  224\n",
      "\n",
      "--- Grau das Tracks na LCC (nÂº de playlists por track) ---\n",
      "MÃ©dia:   8.65\n",
      "Mediana: 1.00\n",
      "MÃ­nimo:  1\n",
      "MÃ¡ximo:  3105\n",
      "\n",
      "======================================================================\n",
      "Redes/matrizes criadas com sucesso!\n",
      "- B: Matriz bipartida completa (playlists x tracks)\n",
      "- B_lcc: Matriz apenas com a LCC (playlists_lcc x tracks_lcc)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# ETAPA 7: Criar matriz bipartida apenas com a LCC\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CRIANDO MATRIZ B APENAS COM A LCC\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1) Recortar B para manter apenas playlists e tracks da LCC\n",
    "B_lcc = B[playlists_in_lcc_idx[:, None], tracks_in_lcc_idx]  # forma 1\n",
    "# ou, de forma equivalente e mais legÃ­vel:\n",
    "B_lcc = B[playlists_in_lcc_idx][:, tracks_in_lcc_idx]\n",
    "\n",
    "# 2) Ãndices (ids) correspondentes\n",
    "p_index_lcc = p_index[playlists_in_lcc_idx]  # pids na LCC\n",
    "m_index_lcc = m_index[tracks_in_lcc_idx]     # track_uris na LCC\n",
    "\n",
    "print(f\"\\nMatriz B_lcc criada!\")\n",
    "nP_lcc, nM_lcc = B_lcc.shape\n",
    "nnz_lcc = B_lcc.nnz\n",
    "\n",
    "print(f\"Playlists na LCC: {nP_lcc:,}\")\n",
    "print(f\"Tracks na LCC: {nM_lcc:,}\")\n",
    "print(f\"Total de nÃ³s na LCC: {nP_lcc + nM_lcc:,}\")\n",
    "print(f\"Total de arestas na LCC: {nnz_lcc:,}\")\n",
    "\n",
    "density_lcc = nnz_lcc / (nP_lcc * nM_lcc) if nP_lcc * nM_lcc > 0 else 0.0\n",
    "print(f\"Densidade da LCC: {density_lcc:.6e}\")\n",
    "\n",
    "# 3) EstatÃ­sticas de grau na LCC\n",
    "#    Playlist: nÂº de mÃºsicas; Track: nÂº de playlists\n",
    "\n",
    "# CSR: indptr => graus por linha (playlists)\n",
    "playlist_degrees_lcc = np.diff(B_lcc.indptr)\n",
    "\n",
    "# Colunas: converter para CSC para obter graus por coluna (tracks)\n",
    "B_lcc_csc = B_lcc.tocsc()\n",
    "track_degrees_lcc = np.diff(B_lcc_csc.indptr)\n",
    "\n",
    "print(f\"\\n--- Grau das Playlists na LCC (nÂº de mÃºsicas por playlist) ---\")\n",
    "print(f\"MÃ©dia:   {np.mean(playlist_degrees_lcc):.2f}\")\n",
    "print(f\"Mediana: {np.median(playlist_degrees_lcc):.2f}\")\n",
    "print(f\"MÃ­nimo:  {np.min(playlist_degrees_lcc)}\")\n",
    "print(f\"MÃ¡ximo:  {np.max(playlist_degrees_lcc)}\")\n",
    "\n",
    "print(f\"\\n--- Grau das Tracks na LCC (nÂº de playlists por track) ---\")\n",
    "print(f\"MÃ©dia:   {np.mean(track_degrees_lcc):.2f}\")\n",
    "print(f\"Mediana: {np.median(track_degrees_lcc):.2f}\")\n",
    "print(f\"MÃ­nimo:  {np.min(track_degrees_lcc)}\")\n",
    "print(f\"MÃ¡ximo:  {np.max(track_degrees_lcc)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Redes/matrizes criadas com sucesso!\")\n",
    "print(\"- B: Matriz bipartida completa (playlists x tracks)\")\n",
    "print(\"- B_lcc: Matriz apenas com a LCC (playlists_lcc x tracks_lcc)\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea23f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando grafos em: /Users/lucasborges/Downloads/TCC/graphs/bipartite\n",
      "Arquivos bipartidos salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import save_npz\n",
    "\n",
    "# Definir pasta base para grafos bipartidos\n",
    "base_path = P['graphs_bipartite']\n",
    "\n",
    "print(f\"Salvando grafos em: {base_path}\")\n",
    "\n",
    "# 1. Salvar Matrizes Esparsas\n",
    "save_npz(base_path / \"B_full.npz\", B)\n",
    "save_npz(base_path / \"B_lcc.npz\", B_lcc)\n",
    "\n",
    "# 2. Salvar Ãndices (Series -> DataFrame -> Parquet)\n",
    "# Full Graph Indices\n",
    "p_index.to_frame(name=\"pid\").to_parquet(base_path / \"p_index.parquet\")\n",
    "m_index.to_frame(name=\"track_uri\").to_parquet(base_path / \"m_index.parquet\")\n",
    "\n",
    "# Largest Connected Component (LCC) Indices\n",
    "p_index_lcc.to_frame(name=\"pid\").to_parquet(base_path / \"p_index_lcc.parquet\")\n",
    "m_index_lcc.to_frame(name=\"track_uri\").to_parquet(base_path / \"m_index_lcc.parquet\")\n",
    "\n",
    "print(\"Arquivos bipartidos salvos com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
